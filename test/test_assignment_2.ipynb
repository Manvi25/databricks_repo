{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a95db057-5de7-4fc7-b485-be14e3d9a5c2",
     "showTitle": true,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import unittest\n",
    "import requests\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType, MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4795f099-dbb1-4e63-a8cb-6a99ece29aef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class assignment2(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.spark = SparkSession.builder.appName(\"PySpark Assignment\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfac69cd-d514-4b30-8ded-dda5c62f8f09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def assertion_create_df(self):\n",
    "        response_data = requests.get('https://reqres.in/api/users?page=2')\n",
    "        data = response_data.json()\n",
    "        json_schema = StructType([\n",
    "            StructField(\"page\", IntegerType(), True),\n",
    "            StructField(\"per_page\", IntegerType(), True),\n",
    "            StructField(\"total\", IntegerType(), True),\n",
    "            StructField(\"total_pages\", IntegerType(), True),\n",
    "            StructField(\"data\", StructType([\n",
    "                StructField(\"id\", IntegerType(), True),\n",
    "                StructField(\"email\", StringType(), True),\n",
    "                StructField(\"first_name\", StringType(), True),\n",
    "                StructField(\"last_name\", StringType(), True),\n",
    "                StructField(\"avatar\", StringType(), True)\n",
    "            ]), True),\n",
    "            StructField(\"support\", StructType([\n",
    "                StructField(\"url\", StringType(), True),\n",
    "                StructField(\"text\", StringType(), True)\n",
    "            ]), True)\n",
    "        ])\n",
    "        expected_df = spark.createDataFrame([data],schema=json_schema)\n",
    "        actual_df = create_df(data,json_schema)\n",
    "        self.assertEqual( actual_df ,expected_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53a4faa0-c8f4-424d-98eb-1ec39530120f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def assertion_col_drop(self):\n",
    "        response_data = requests.get('https://reqres.in/api/users?page=2')\n",
    "        json_data = response_data.json()\n",
    "        data_schema = StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"email\", StringType(), True),\n",
    "            StructField(\"first_name\", StringType(), True),\n",
    "            StructField(\"last_name\", StringType(), True),\n",
    "            StructField(\"avatar\", StringType(), True)\n",
    "        ])\n",
    "        custom_schema = StructType([\n",
    "            StructField(\"page\", IntegerType(), True),\n",
    "            StructField(\"per_page\", IntegerType(), True),\n",
    "            StructField(\"total\", IntegerType(), True),\n",
    "            StructField(\"total_pages\", IntegerType(), True),\n",
    "            StructField(\"data\", ArrayType(data_schema), True),\n",
    "            StructField(\"support\", MapType(StringType(), StringType()), True)\n",
    "        ])\n",
    "        actual_df = spark.createDataFrame([json_data], custom_schema)\n",
    "        expected_df = actual_df.drop('page', 'per_page', 'total', 'total_pages', 'support')\n",
    "        result_df = col_drop(actual_df)\n",
    "        self.assertEqual( actual_df ,expected_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c137bf4-08d4-455b-ac89-6771bc9308b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n----------------------------------------------------------------------\nRan 0 tests in 0.000s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: <unittest.runner.TextTestResult run=0 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "suite = unittest.TestLoader().loadTestsFromTestCase(assignment2)\n",
    "unittest.TextTestRunner(verbosity=1).run(suite)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test_2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
